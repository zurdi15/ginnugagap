#
# WARNING: Make sure to use the docker-compose.yml of the current release:
#
# https://github.com/immich-app/immich/releases/latest/download/docker-compose.yml
#
# The compose file on main may not be compatible with the latest release.
#

name: immich

services:
  immich-server:
    container_name: immich_server
    image: ${IMMICH_SERVER_IMAGE}
    command: ['start.sh', 'immich']
    environment:
      DB_PASSWORD: ${DB_PASSWORD}
      DB_USERNAME: ${DB_USERNAME}
      DB_DATABASE_NAME: ${DB_DATABASE_NAME}
    volumes:
      - ${SYS_LIBRARY_PATH}:${CON_LIBRARY_PATH}
      - ${SYS_UPLOAD_PATH}:${CON_UPLOAD_PATH}
      - /etc/localtime:/etc/localtime:ro
    ports:
      - 2283:3001
    depends_on:
      - redis
      - database
    restart: "unless-stopped"

  immich-microservices:
    container_name: immich_microservices
    image: ${IMMICH_SERVER_IMAGE}
    # extends: # uncomment this section for hardware acceleration - see https://immich.app/docs/features/hardware-transcoding
    #   file: hwaccel.transcoding.yml
    #   service: cpu # set to one of [nvenc, quicksync, rkmpp, vaapi, vaapi-wsl] for accelerated transcoding
    command: ['start.sh', 'microservices']
    environment:
      DB_PASSWORD: ${DB_PASSWORD}
      DB_USERNAME: ${DB_USERNAME}
      DB_DATABASE_NAME: ${DB_DATABASE_NAME}
    volumes:
      - ${SYS_LIBRARY_PATH}:${CON_LIBRARY_PATH}
      - ${SYS_UPLOAD_PATH}:${CON_UPLOAD_PATH}
      - /etc/localtime:/etc/localtime:ro
    depends_on:
      - redis
      - database
    restart: "unless-stopped"

  # immich-machine-learning:
  #   container_name: immich_machine_learning
  #   # For hardware acceleration, add one of -[armnn, cuda, openvino] to the image tag.
  #   # Example tag: ${IMMICH_VERSION:-release}-cuda
  #   image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}
  #   # extends: # uncomment this section for hardware acceleration - see https://immich.app/docs/features/ml-hardware-acceleration
  #   #   file: hwaccel.ml.yml
  #   #   service: cpu # set to one of [armnn, cuda, openvino, openvino-wsl] for accelerated inference - use the `-wsl` version for WSL2 where applicable
  #   volumes:
  #     - model-cache:/cache
  #   restart: "unless-stopped"

  redis:
    container_name: immich_redis
    image: ${REDIS_IMAGE}
    restart: "unless-stopped"

  database:
    container_name: immich_postgres
    image: ${IMMICH_DB_IMAGE}
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_DB: ${DB_DATABASE_NAME}
    volumes:
      - ${SYS_DB_PATH}:${CON_DB_PATH}
    restart: "unless-stopped"

# volumes:
#   model-cache:
